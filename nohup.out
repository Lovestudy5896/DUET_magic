2025-04-09 18:23:45 [INFO] ts_benchmark.data.data_source(124): Start loading 1 series in parallel
2025-04-09 18:23:50 [INFO] ts_benchmark.data.data_source(133): Data loading finished.
2025-04-09 18:23:50 [INFO] ts_benchmark.data.suites.global_storage(40): Data server starting...
2025-04-09 18:23:50 [INFO] ts_benchmark.data.suites.global_storage(41): Start sending data to the global storage.
2025-04-09 18:23:50 [INFO] ts_benchmark.data.suites.global_storage(46): Notifying all workers to sync data from the global storage.
2025-04-09 18:23:50 [INFO] ts_benchmark.data.suites.global_storage(49): Data server started.
2025-04-09 18:23:50 [INFO] ts_benchmark.models.model_loader(98): Trying to load model ts_benchmark.baselines.duet.DUET

scheduling DUET:   0%|          | 0/1 [00:00<?, ?it/s]Traceback (most recent call last):
scheduling DUET:   0%|          | 0/1 [29:26<?, ?it/s]
{'CI': 1,
 'activation': 'gelu',
 'batch_size': 16,
 'c_out': 321,
 'capacity_factor': 1.25,
 'd_ff': 1024,
 'd_layers': 1,
 'd_model': 512,
 'dec_in': 321,
 'dropout': 0.5,
 'e_layers': 4,
 'enc_in': 321,
 'factor': 3,
 'fc_dropout': 0,
 'freq': 'h',
 'hidden_size': 256,
 'horizon': 96,
 'k': 2,
 'label_len': 256,
 'loss': 'MAE',
 'lr': 0.0005,
 'lradj': 'type1',
 'moving_avg': 25,
 'n_heads': 1,
 'noisy_gating': True,
 'norm': True,
 'num_epochs': 100,
 'num_experts': 4,
 'num_workers': 0,
 'output_attention': 0,
 'patch_len': 48,
 'patience': 5,
 'period_len': 4,
 'seg_len': 6,
 'seq_len': 512,
 'stride': 8,
 'win_size': 2}
{'CI': 1,
 'activation': 'gelu',
 'batch_size': 16,
 'c_out': 321,
 'capacity_factor': 1.25,
 'd_ff': 1024,
 'd_layers': 1,
 'd_model': 512,
 'dec_in': 321,
 'dropout': 0.5,
 'e_layers': 4,
 'enc_in': 321,
 'factor': 3,
 'fc_dropout': 0,
 'freq': 'h',
 'hidden_size': 256,
 'horizon': 96,
 'k': 2,
 'label_len': 256,
 'loss': 'MAE',
 'lr': 0.0005,
 'lradj': 'type1',
 'moving_avg': 25,
 'n_heads': 1,
 'noisy_gating': True,
 'norm': True,
 'num_epochs': 100,
 'num_experts': 4,
 'num_workers': 0,
 'output_attention': 0,
 'patch_len': 48,
 'patience': 5,
 'period_len': 4,
 'seg_len': 6,
 'seq_len': 512,
 'stride': 8,
 'win_size': 2}
{'CI': 1,
 'activation': 'gelu',
 'batch_size': 16,
 'c_out': 321,
 'capacity_factor': 1.25,
 'd_ff': 1024,
 'd_layers': 1,
 'd_model': 512,
 'dec_in': 321,
 'dropout': 0.5,
 'e_layers': 4,
 'enc_in': 321,
 'factor': 3,
 'fc_dropout': 0,
 'freq': 'h',
 'hidden_size': 256,
 'horizon': 96,
 'k': 2,
 'label_len': 256,
 'loss': 'MAE',
 'lr': 0.0005,
 'lradj': 'type1',
 'moving_avg': 25,
 'n_heads': 1,
 'noisy_gating': True,
 'norm': True,
 'num_epochs': 100,
 'num_experts': 4,
 'num_workers': 0,
 'output_attention': 0,
 'patch_len': 48,
 'patience': 5,
 'period_len': 4,
 'seg_len': 6,
 'seq_len': 512,
 'stride': 8,
 'win_size': 2}
{'CI': 1,
 'activation': 'gelu',
 'batch_size': 16,
 'c_out': 321,
 'capacity_factor': 1.25,
 'd_ff': 1024,
 'd_layers': 1,
 'd_model': 512,
 'dec_in': 321,
 'dropout': 0.5,
 'e_layers': 4,
 'enc_in': 321,
 'factor': 3,
 'fc_dropout': 0,
 'freq': 'h',
 'hidden_size': 256,
 'horizon': 96,
 'k': 2,
 'label_len': 256,
 'loss': 'MAE',
 'lr': 0.0005,
 'lradj': 'type1',
 'moving_avg': 25,
 'n_heads': 1,
 'noisy_gating': True,
 'norm': True,
 'num_epochs': 100,
 'num_experts': 4,
 'num_workers': 0,
 'output_attention': 0,
 'patch_len': 48,
 'patience': 5,
 'period_len': 4,
 'seg_len': 6,
 'seq_len': 512,
 'stride': 8,
 'win_size': 2}
{'CI': 1,
 'activation': 'gelu',
 'batch_size': 16,
 'c_out': 321,
 'capacity_factor': 1.25,
 'd_ff': 1024,
 'd_layers': 1,
 'd_model': 512,
 'dec_in': 321,
 'dropout': 0.5,
 'e_layers': 4,
 'enc_in': 321,
 'factor': 3,
 'fc_dropout': 0,
 'freq': 'h',
 'hidden_size': 256,
 'horizon': 96,
 'k': 2,
 'label_len': 256,
 'loss': 'MAE',
 'lr': 0.0005,
 'lradj': 'type1',
 'moving_avg': 25,
 'n_heads': 1,
 'noisy_gating': True,
 'norm': True,
 'num_epochs': 100,
 'num_experts': 4,
 'num_workers': 0,
 'output_attention': 0,
 'patch_len': 48,
 'patience': 5,
 'period_len': 4,
 'seg_len': 6,
 'seq_len': 512,
 'stride': 8,
 'win_size': 2}
---------------------------------------------------------- DUET
Total trainable parameters: 11418867
Traceback (most recent call last):
  File "/home/stu/DUET_TC/./scripts/run_benchmark.py", line 348, in <module>
    log_filenames = pipeline(
  File "/home/stu/DUET_TC/ts_benchmark/pipeline.py", line 144, in pipeline
    result_list = [
  File "/home/stu/DUET_TC/ts_benchmark/pipeline.py", line 145, in <listcomp>
    eval_model(model_factory, data_name_list, evaluation_config)
  File "/home/stu/DUET_TC/ts_benchmark/evaluation/evaluate_model.py", line 158, in eval_model
    eval_backend.schedule(strategy.execute, (series_name, model_factory))
  File "/home/stu/DUET_TC/ts_benchmark/utils/parallel/__init__.py", line 57, in schedule
    return self.backend.schedule(fn, args, timeout)
  File "/home/stu/DUET_TC/ts_benchmark/utils/parallel/sequential_backend.py", line 51, in schedule
    res.put(fn(*args))
  File "/home/stu/DUET_TC/ts_benchmark/evaluation/strategy/forecasting.py", line 54, in execute
    single_series_results = self._execute(
  File "/home/stu/DUET_TC/ts_benchmark/evaluation/strategy/rolling_forecast.py", line 199, in _execute
    return self._eval_batch(series, meta_info, model, series_name)
  File "/home/stu/DUET_TC/ts_benchmark/evaluation/strategy/rolling_forecast.py", line 309, in _eval_batch
    fit_method(train_valid_data, train_ratio_in_tv=train_ratio_in_tv)
  File "/home/stu/DUET_TC/ts_benchmark/baselines/duet/duet.py", line 318, in forecast_fit
    output, loss_importance = self.model(input)
  File "/home/stu/miniconda3/envs/DUET/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/stu/miniconda3/envs/DUET/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/stu/DUET_TC/ts_benchmark/baselines/duet/models/duet_model.py", line 58, in forward
    channel_group_feature, attention = self.Channel_transformer(x=temporal_feature, attn_mask=channel_mask)
  File "/home/stu/miniconda3/envs/DUET/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/stu/miniconda3/envs/DUET/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/stu/DUET_TC/ts_benchmark/baselines/duet/utils/masked_attention.py", line 59, in forward
    x, attn = attn_layer(x, attn_mask=attn_mask, tau=tau, delta=delta)
  File "/home/stu/miniconda3/envs/DUET/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/stu/miniconda3/envs/DUET/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/stu/DUET_TC/ts_benchmark/baselines/duet/utils/masked_attention.py", line 33, in forward
    y = self.dropout(self.activation(self.conv1(y.transpose(-1, 1))))
  File "/home/stu/miniconda3/envs/DUET/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/stu/miniconda3/envs/DUET/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/stu/miniconda3/envs/DUET/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 308, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/stu/miniconda3/envs/DUET/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 304, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
KeyboardInterrupt
